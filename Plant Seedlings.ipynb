{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_file(url, out_file):\n",
    "\n",
    "    chunk_size = 1024\n",
    "    r = requests.get(url, stream=True)\n",
    "    total_size = int(r.headers['content-length'])\n",
    "\n",
    "    with open(out_file, 'wb') as f:\n",
    "        for data in tqdm(iterable=r.iter_content(chunk_size=chunk_size),\n",
    "                         total=total_size/chunk_size, unit='KB'):\n",
    "            f.write(data)\n",
    "\n",
    "    print('{} download Complete!'.format(out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://vision.eng.au.dk/?download=/data/WeedData/NonsegmentedV2.zip'\n",
    "zip_file = './data.zip'\n",
    "data_path = './data'\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.isfile(zip_file):\n",
    "    download_file(url, zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "if not os.path.isdir(data_path):\n",
    "    with ZipFile(zip_file, 'r') as f:\n",
    "        print('Extracting all the files now ...')\n",
    "        f.extractall('./data')\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = os.listdir(data_path)\n",
    "num_labels = len(labels_list)\n",
    "\n",
    "print('Labels:')\n",
    "\n",
    "for idx, label in enumerate(labels_list):\n",
    "    print('{}. {}'.format(idx+1, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "print('No of images in:')\n",
    "\n",
    "for idx, label in enumerate(labels_list):\n",
    "    label_path = os.path.join(data_path, label)\n",
    "    images_list = glob.glob(os.path.join(label_path, '*.png'))\n",
    "    num_images = len(images_list)\n",
    "    X += images_list\n",
    "    y += [label] * num_images\n",
    "    img_path = images_list[0]\n",
    "    img = plt.imread(img_path)\n",
    "\n",
    "    plt.subplot(3,4,idx+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "\n",
    "    print('{} directory: {}'.format(label, num_images))\n",
    "\n",
    "print()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=86)\n",
    "plt.xlabel('labels')\n",
    "plt.ylabel('no of images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './output_data'\n",
    "log_file = os.path.join(output_path, 'log.csv')\n",
    "\n",
    "model_path = os.path.join(output_path, 'plant_vgg19.h5')\n",
    "weights_path = os.path.join(output_path, 'plant_vgg19_weights.h5')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "n_splits = 5\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize all images# Load  \n",
    "\n",
    "print(\"Loading images...\")\n",
    "\n",
    "temp = []\n",
    "\n",
    "for filename in X:\n",
    "    img = image.load_img(filename, target_size=(299, 299, 3))\n",
    "    img = image.img_to_array(img) * (0.00392156862745098)\n",
    "    temp.append(img)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "\n",
    "X = np.array(temp)  # Matrix of (m x 299 x 299 x 3)\n",
    "X = preprocess_input(X)  # Preprocess using VGG19 preprocess_input\n",
    "y = np.array(y)  # Convert target to numpy array of m x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y.reshape((y.shape[0], 1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "X, X_valid, y, y_valid = train_test_split(X, y, test_size=0.1,\n",
    "                                          random_state=0, stratify=y)\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                        random_state=0, stratify=y)\n",
    "\n",
    "print('Train:', len(X), len(y))\n",
    "print('Valid:', len(X_valid), len(y_valid))\n",
    "print('Test:', len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# include_top is used to remove all the layers after block conv5\n",
    "\n",
    "model = VGG19(include_top=False, input_shape=img.shape)\n",
    "\n",
    "# Freeze all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# re-add the removed layers\n",
    "x = model.output\n",
    "x = Flatten(name=\"flatten\")(x)\n",
    "x = Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n",
    "x = Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n",
    "x = Dense(num_labels, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "# Redefine the model\n",
    "model = Model(inputs=model.input, outputs=x, name=\"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def precision_micro(y_true, y_pred):\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fp = K.sum(y_pred * K.cast(K.equal(y_true, K.zeros_like(y_true)), \"float32\"))\n",
    "    return tp / (tp + fp + K.epsilon())\n",
    "\n",
    "\n",
    "def recall_micro(y_true, y_pred):\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fn = K.sum(y_true * K.cast(K.equal(y_pred, K.zeros_like(y_pred)), \"float32\"))\n",
    "    return tp / (tp + fn + K.epsilon())\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    y_pred = K.argmax(y_pred, axis=-1)\n",
    "    y_pred = K.one_hot(y_pred, 12)\n",
    "    pm = precision_micro(y_true, y_pred)\n",
    "    rm = recall_micro(y_true, y_pred)\n",
    "    return (2 * pm * rm) / (pm + rm + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y).astype(np.int32)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.0001)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', f1_micro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import TerminateOnNaN\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# TerminateOnNaN\n",
    "terminate_callback = TerminateOnNaN()\n",
    "\n",
    "# Tensorboard\n",
    "tb_callback = TensorBoard('./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# Model Checkppoint\n",
    "ckpt_callback = ModelCheckpoint('./weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                                verbose=1, save_weights_only=False, mode='auto', period=5)\n",
    "\n",
    "# Early Stopping\n",
    "#stopping_callback = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "\n",
    "# CSV Logger\n",
    "csv_logger = CSVLogger('./training.log')\n",
    "\n",
    "# Callbacks list\n",
    "callbacks = [terminate_callback, tb_callback, ckpt_callback, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a splitter\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Training\n",
    "print(\"Start cross-validation training...\")\n",
    "histories = []\n",
    "for train, val in skf.split(X, y):\n",
    "    Xtrain = X[train, :]\n",
    "    ytrain = to_categorical(y[train,], num_classes = num_labels)\n",
    "    Xval = X[val, :]\n",
    "    yval = to_categorical(y[val,], num_classes = num_labels)\n",
    "    history = model.fit(Xtrain, ytrain, batch_size=batch_size, \n",
    "                        epochs=epochs, validation_data=(Xval, yval))\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "print(\"Full training...\")\n",
    "\n",
    "ytrain = to_categorical(y, num_classes = num_labels)\n",
    "history = model.fit(X, ytrain, batch_size=batch_size, epochs=epochs, \n",
    "                   callbacks = callbacks, validation_data=(X_valid, y_valid))\n",
    "histories.append(history)\n",
    "\n",
    "print(\"Save whole model...\")\n",
    "model.save(model_path)\n",
    "\n",
    "print(\"Save weights of the model\")\n",
    "model.save(weights_path)\n",
    "\n",
    "with open(log_file, \"w\") as f:\n",
    "    json.dump(histories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes = num_labels)\n",
    "\n",
    "Eval = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(Eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
